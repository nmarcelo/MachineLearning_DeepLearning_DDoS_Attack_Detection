# -*- coding: utf-8 -*-
"""SVM2017.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dX-cMC-5tIp9cN6kRpFGddKJ-JpTMeBk
"""

pip install scikit-plot

# main libraries
import pandas as pd
import numpy as np
import time
# visual libraries
from matplotlib import pyplot as plt
# sklearn libraries
from sklearn import svm
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, classification_report, roc_curve
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn import metrics
import joblib


import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV

import scikitplot as skplt

df  = pd.read_csv('/content/drive/My Drive/TecM/Noveno Semestre/Tesina/DDoS Warriors/GrupoEstudiantesAgo-Dic2020/DataSets/CICDoS2017/Pre-processed/dataTrain.csv')
df_test  = pd.read_csv('/content/drive/My Drive/TecM/Noveno Semestre/Tesina/DDoS Warriors/GrupoEstudiantesAgo-Dic2020/DataSets/CICDoS2017/Pre-processed/dataTest.csv')

df.drop(columns=['Unnamed: 0','Protocol','Src.IP','Src.Port','Dst.IP','Dst.Port'])

df_test.drop(columns=['Unnamed: 0','Protocol','Src.IP','Src.Port','Dst.IP','Dst.Port'])

y = df.loc[:,['Label']].values
y_test = df_test.loc[:,['Label']].values

"""Load Principal Components"""

x = df.loc[:, ['Flow.Duration','Tot.Fwd.Pkts','Tot.Bwd.Pkts','TotLen.Fwd.Pkts',
               'TotLen.Bwd.Pkts','Fwd.Pkt.Len.Max','Fwd.Pkt.Len.Min',
               'Fwd.Pkt.Len.Std','Bwd.Pkt.Len.Max','Bwd.Pkt.Len.Min',
               'Bwd.Pkt.Len.Std','Flow.Byts.s','Flow.Pkts.s','Flow.IAT.Mean',
               'Flow.IAT.Std','Flow.IAT.Max','Flow.IAT.Min','Fwd.IAT.Mean',
               'Fwd.IAT.Std','Fwd.IAT.Min','Bwd.IAT.Tot','Bwd.IAT.Mean',
               'Bwd.IAT.Std','Bwd.IAT.Max','Bwd.IAT.Min','Fwd.PSH.Flags',
               'Fwd.Pkts.s','Bwd.Pkts.s','Pkt.Len.Min','Pkt.Len.Max',
               'Pkt.Len.Mean','Pkt.Len.Std','Pkt.Len.Var','FIN.Flag.Cnt',
               'SYN.Flag.Cnt','RST.Flag.Cnt','PSH.Flag.Cnt','Down.Up.Ratio',
               'Bwd.Pkts.b.Avg','Bwd.Blk.Rate.Avg','Subflow.Fwd.Pkts',
               'Subflow.Fwd.Byts','Subflow.Bwd.Byts','Init.Fwd.Win.Byts',
               'Init.Bwd.Win.Byts','Fwd.Seg.Size.Min','Idle.Mean','Idle.Std',
               'Idle.Min']].values

x_test = df_test.loc[:, [ 'Flow.Duration','Tot.Fwd.Pkts','Tot.Bwd.Pkts','TotLen.Fwd.Pkts',
               'TotLen.Bwd.Pkts','Fwd.Pkt.Len.Max','Fwd.Pkt.Len.Min',
               'Fwd.Pkt.Len.Std','Bwd.Pkt.Len.Max','Bwd.Pkt.Len.Min',
               'Bwd.Pkt.Len.Std','Flow.Byts.s','Flow.Pkts.s','Flow.IAT.Mean',
               'Flow.IAT.Std','Flow.IAT.Max','Flow.IAT.Min','Fwd.IAT.Mean',
               'Fwd.IAT.Std','Fwd.IAT.Min','Bwd.IAT.Tot','Bwd.IAT.Mean',
               'Bwd.IAT.Std','Bwd.IAT.Max','Bwd.IAT.Min','Fwd.PSH.Flags',
               'Fwd.Pkts.s','Bwd.Pkts.s','Pkt.Len.Min','Pkt.Len.Max',
               'Pkt.Len.Mean','Pkt.Len.Std','Pkt.Len.Var','FIN.Flag.Cnt',
               'SYN.Flag.Cnt','RST.Flag.Cnt','PSH.Flag.Cnt','Down.Up.Ratio',
               'Bwd.Pkts.b.Avg','Bwd.Blk.Rate.Avg','Subflow.Fwd.Pkts',
               'Subflow.Fwd.Byts','Subflow.Bwd.Byts','Init.Fwd.Win.Byts',
               'Init.Bwd.Win.Byts','Fwd.Seg.Size.Min','Idle.Mean','Idle.Std',
               'Idle.Min']].values

x_test.shape

x = StandardScaler().fit_transform(x)
x_test = StandardScaler().fit_transform(x_test)

pca = PCA(.85)
pca.fit(x)
pca.n_components_

joblib.dump(pca, "pca85.joblib")

x_train = pca.transform(x)
y_train = np.ravel(y,order='C')

x_test = pca.transform(x_test)
y_test = np.ravel(y_test,order='C')

print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

clf = svm.SVC(kernel='poly', C=1.4)

#Train the model using the training sets
clf.fit(x_train, y_train)

joblib.dump(clf, "svm2017.joblib")

#Predict the response for test dataset
y_pred = clf.predict(x_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

plt.plot(y_pred)
plt.plot(y_test)

print("Precision:",metrics.precision_score(y_test, y_pred, average='micro'))

# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:",metrics.recall_score(y_test, y_pred, average='micro'))

metrics.plot_confusion_matrix(clf, x_test, y_test, normalize="true",  cmap=plt.cm.Blues)

print("Precision:",metrics.precision_score(y_test, y_pred, average='micro'))

# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:",metrics.recall_score(y_test, y_pred, average='micro'))

TP=TN=FP=FN=0
for k in range (0,len(y_pred)):
    ylabel     = y_test[k];
    ypredicted = y_pred[k];
    if ypredicted == 0 and ylabel == 0:
        TN = TN + 1
    elif ypredicted > 0 and ylabel > 0:
        TP = TP + 1
    elif ypredicted > 0 and ylabel == 0:
        FP = FP + 1
    elif ypredicted == 0 and ylabel > 0:
        FN = FN + 1
    else:
        print('any')
print("ACCURACY", (TP+TN)/(TP+TN+FP+FN))
print("F1-SCORE", (2*TP)/(2*TP+FP+FN))
print("FALSE POS. RATE (FPR)", (FP)/(FP+TN))
print("RECALL (TPR)", (TP)/(TP+FN))

from sklearn.metrics import accuracy_score, recall_score,f1_score,precision_score,roc_auc_score
print("***************************************************************")
print("EVALUATE MODEL ON TESTING DATA")
results = model.evaluate(x_t, y_t)
yhat = model.predict(x_t)
yyhat = []
for k in range (0,len(yhat)):
    yh = np.argmax(yhat[k])
    yyhat.append(yh)
print("***************************************************************")    
print("Assessment: 2 classes") 
TP=TN=FP=FN=0
y_test2c = np.array(y_t)
y_test2c [y_test2c>=1] = 1;
y_hat2c = np.array(yyhat)
y_hat2c [y_hat2c>=1] = 1;
print("Accuracy", accuracy_score(y_test2c, y_hat2c))
print("Precision", precision_score(y_test2c, y_hat2c, average='weighted'))
print("F1-SCORE", f1_score(y_test2c, y_hat2c, average='weighted'))
print("RECALL (TPR)", recall_score(y_test2c, y_hat2c, average='weighted'))
 
for k in range (0,len(yhat)):
    ylabel     = y_t[k];
    ypredicted = yyhat[k];
    if ypredicted == 0 and ylabel == 0:
        TN = TN + 1
    elif ypredicted > 0 and ylabel > 0:
        TP = TP + 1
    elif ypredicted > 0 and ylabel == 0:
        FP = FP + 1
    elif ypredicted == 0 and ylabel > 0:
        FN = FN + 1
    else:
        print('any')

print("FALSE POS. RATE (FPR)", (FP)/(FP+TN))


print("***************************************************************") 
print("Assessment: n classes") 
print("Accuracy", accuracy_score(y_t, yyhat))
print("Precision", precision_score(y_t, yyhat, average='weighted'))
print("F1-SCORE", f1_score(y_t, yyhat, average='weighted'))
print("RECALL (TPR)", recall_score(y_t, yyhat, average='weighted'))

skplt.metrics.plot_confusion_matrix(y_t,yyhat,normalize="True")